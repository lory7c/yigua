#!/usr/bin/env python3
"""
ç³»ç»Ÿæ•´ä½“æ€§èƒ½å’Œæ•°æ®å®Œæ•´æ€§éªŒè¯
å…¨é¢æ£€æŸ¥PDFå¤„ç†ç®¡é“å’Œæ•°æ®åº“çš„å®Œæ•´æ€§
"""

import sqlite3
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import logging

class SystemValidator:
    """ç³»ç»ŸéªŒè¯å™¨"""
    
    def __init__(self, db_path: str, results_file: str):
        self.db_path = db_path
        self.results_file = results_file
        self.logger = self._setup_logging()
        
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger("SystemValidator")
        logger.setLevel(logging.INFO)
        
        for handler in logger.handlers:
            logger.removeHandler(handler)
        
        console_handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        return logger
    
    def validate_database_integrity(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®åº“å®Œæ•´æ€§"""
        self.logger.info("ğŸ” éªŒè¯æ•°æ®åº“å®Œæ•´æ€§...")
        
        validation_results = {
            "database_exists": False,
            "table_counts": {},
            "data_consistency": {},
            "index_status": {},
            "foreign_key_integrity": True,
            "issues": []
        }
        
        try:
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶å­˜åœ¨
            if not Path(self.db_path).exists():
                validation_results["issues"].append("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
                return validation_results
            
            validation_results["database_exists"] = True
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨å­˜åœ¨æ€§å’Œè®°å½•æ•°
            expected_tables = [
                'pdf_documents', 'extracted_content', 'hexagrams',
                'yao_content', 'cases', 'keywords', 'processing_stats'
            ]
            
            for table in expected_tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    validation_results["table_counts"][table] = count
                    
                    if count == 0 and table != 'processing_stats':
                        validation_results["issues"].append(f"è¡¨ {table} æ²¡æœ‰æ•°æ®")
                        
                except sqlite3.Error as e:
                    validation_results["issues"].append(f"è¡¨ {table} ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥: {e}")
                    validation_results["table_counts"][table] = -1
            
            # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
            try:
                # æ–‡æ¡£å’Œå†…å®¹å¯¹åº”å…³ç³»
                cursor.execute("""
                SELECT 
                    (SELECT COUNT(*) FROM pdf_documents) as docs,
                    (SELECT COUNT(*) FROM extracted_content) as contents
                """)
                docs, contents = cursor.fetchone()
                
                if docs == contents:
                    validation_results["data_consistency"]["doc_content_match"] = True
                else:
                    validation_results["data_consistency"]["doc_content_match"] = False
                    validation_results["issues"].append(f"æ–‡æ¡£æ•°({docs})ä¸å†…å®¹æ•°({contents})ä¸åŒ¹é…")
                
                # å¤–é”®å®Œæ•´æ€§æ£€æŸ¥
                cursor.execute("""
                SELECT COUNT(*) FROM hexagrams h 
                LEFT JOIN pdf_documents d ON h.document_id = d.id 
                WHERE d.id IS NULL
                """)
                orphaned_hexagrams = cursor.fetchone()[0]
                
                if orphaned_hexagrams > 0:
                    validation_results["foreign_key_integrity"] = False
                    validation_results["issues"].append(f"{orphaned_hexagrams} ä¸ªå¦è±¡è®°å½•ç¼ºå°‘å¯¹åº”æ–‡æ¡£")
                
            except Exception as e:
                validation_results["issues"].append(f"æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            
            # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
            try:
                cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
                indexes = [row[0] for row in cursor.fetchall()]
                validation_results["index_status"] = {
                    "total_indexes": len(indexes),
                    "index_list": indexes
                }
            except Exception as e:
                validation_results["issues"].append(f"ç´¢å¼•æ£€æŸ¥å¤±è´¥: {e}")
            
            conn.close()
            
        except Exception as e:
            validation_results["issues"].append(f"æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        
        return validation_results
    
    def validate_processing_results(self) -> Dict[str, Any]:
        """éªŒè¯å¤„ç†ç»“æœ"""
        self.logger.info("ğŸ“Š éªŒè¯å¤„ç†ç»“æœ...")
        
        validation_results = {
            "file_exists": False,
            "json_valid": False,
            "summary_complete": False,
            "results_count": 0,
            "successful_results": 0,
            "failed_results": 0,
            "categories_found": [],
            "methods_used": [],
            "issues": []
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
            if not Path(self.results_file).exists():
                validation_results["issues"].append("å¤„ç†ç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
                return validation_results
            
            validation_results["file_exists"] = True
            
            # åŠ è½½JSONæ•°æ®
            with open(self.results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            validation_results["json_valid"] = True
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['status', 'summary', 'results']
            for field in required_fields:
                if field not in data:
                    validation_results["issues"].append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            if 'summary' in data:
                summary = data['summary']
                required_summary_fields = [
                    'total_files', 'successful_files', 'failed_files', 
                    'success_rate', 'processing_time_minutes'
                ]
                
                summary_complete = all(field in summary for field in required_summary_fields)
                validation_results["summary_complete"] = summary_complete
                
                if not summary_complete:
                    validation_results["issues"].append("æ‘˜è¦ä¿¡æ¯ä¸å®Œæ•´")
            
            if 'results' in data:
                results = data['results']
                validation_results["results_count"] = len(results)
                
                successful = [r for r in results if r.get('status') == 'success']
                failed = [r for r in results if r.get('status') == 'failed']
                
                validation_results["successful_results"] = len(successful)
                validation_results["failed_results"] = len(failed)
                
                # ç»Ÿè®¡åˆ†ç±»å’Œæ–¹æ³•
                categories = set()
                methods = set()
                
                for result in successful:
                    if 'category' in result:
                        categories.add(result['category'])
                    if 'method_used' in result:
                        methods.add(result['method_used'])
                
                validation_results["categories_found"] = list(categories)
                validation_results["methods_used"] = list(methods)
                
                # æ£€æŸ¥ç»“æ„åŒ–å†…å®¹
                structured_content_count = 0
                for result in successful:
                    if 'structured_content' in result:
                        structured_content_count += 1
                
                if structured_content_count < len(successful):
                    validation_results["issues"].append(f"{len(successful) - structured_content_count} ä¸ªæˆåŠŸç»“æœç¼ºå°‘ç»“æ„åŒ–å†…å®¹")
            
        except json.JSONDecodeError as e:
            validation_results["issues"].append(f"JSONæ ¼å¼æ— æ•ˆ: {e}")
        except Exception as e:
            validation_results["issues"].append(f"å¤„ç†ç»“æœéªŒè¯å¤±è´¥: {e}")
        
        return validation_results
    
    def performance_benchmark(self) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        self.logger.info("âš¡ æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        benchmark_results = {
            "database_performance": {},
            "query_times": {},
            "overall_score": 0,
            "recommendations": []
        }
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åŸºæœ¬æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
            queries = {
                "ç®€å•è®¡æ•°æŸ¥è¯¢": "SELECT COUNT(*) FROM pdf_documents",
                "åˆ†ç±»ç»Ÿè®¡æŸ¥è¯¢": "SELECT category, COUNT(*) FROM pdf_documents GROUP BY category",
                "å…³é”®è¯æœç´¢": "SELECT COUNT(*) FROM keywords WHERE keyword LIKE '%é˜´é˜³%'",
                "è¿æ¥æŸ¥è¯¢": """
                    SELECT d.file_name, COUNT(k.keyword) as keyword_count 
                    FROM pdf_documents d 
                    LEFT JOIN keywords k ON d.id = k.document_id 
                    GROUP BY d.id 
                    LIMIT 10
                """,
                "å¤æ‚èšåˆæŸ¥è¯¢": """
                    SELECT 
                        d.category,
                        COUNT(d.id) as doc_count,
                        AVG(c.text_length) as avg_text_length,
                        COUNT(h.id) as hexagram_count
                    FROM pdf_documents d
                    LEFT JOIN extracted_content c ON d.id = c.document_id
                    LEFT JOIN hexagrams h ON d.id = h.document_id
                    GROUP BY d.category
                """
            }
            
            for query_name, query_sql in queries.items():
                start_time = time.time()
                try:
                    cursor.execute(query_sql)
                    cursor.fetchall()
                    query_time = time.time() - start_time
                    benchmark_results["query_times"][query_name] = round(query_time, 4)
                except Exception as e:
                    benchmark_results["query_times"][query_name] = f"å¤±è´¥: {e}"
            
            # æ•°æ®åº“å¤§å°
            cursor.execute("PRAGMA page_size")
            page_size = cursor.fetchone()[0]
            
            cursor.execute("PRAGMA page_count")
            page_count = cursor.fetchone()[0]
            
            db_size_bytes = page_size * page_count
            benchmark_results["database_performance"]["size_mb"] = round(db_size_bytes / (1024 * 1024), 2)
            
            # æ€§èƒ½è¯„åˆ†
            avg_query_time = sum(
                t for t in benchmark_results["query_times"].values() 
                if isinstance(t, (int, float))
            ) / len([t for t in benchmark_results["query_times"].values() if isinstance(t, (int, float))])
            
            if avg_query_time < 0.01:
                score = 10
            elif avg_query_time < 0.1:
                score = 8
            elif avg_query_time < 0.5:
                score = 6
            elif avg_query_time < 1.0:
                score = 4
            else:
                score = 2
            
            benchmark_results["overall_score"] = score
            
            # æ€§èƒ½å»ºè®®
            if avg_query_time > 0.1:
                benchmark_results["recommendations"].append("è€ƒè™‘æ·»åŠ æ›´å¤šç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½")
            
            if db_size_bytes > 100 * 1024 * 1024:  # 100MB
                benchmark_results["recommendations"].append("æ•°æ®åº“è¾ƒå¤§ï¼Œè€ƒè™‘å®šæœŸç»´æŠ¤å’Œä¼˜åŒ–")
            
            conn.close()
            
        except Exception as e:
            benchmark_results["error"] = str(e)
        
        return benchmark_results
    
    def generate_validation_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´éªŒè¯æŠ¥å‘Š"""
        self.logger.info("ğŸ“‹ ç”Ÿæˆç³»ç»ŸéªŒè¯æŠ¥å‘Š...")
        
        start_time = time.time()
        
        # æ‰§è¡Œå„é¡¹éªŒè¯
        db_validation = self.validate_database_integrity()
        results_validation = self.validate_processing_results()
        performance_benchmark = self.performance_benchmark()
        
        validation_time = time.time() - start_time
        
        # è®¡ç®—æ•´ä½“å¥åº·åº¦
        health_score = 0
        max_score = 100
        
        # æ•°æ®åº“å®Œæ•´æ€§ (40åˆ†)
        if db_validation["database_exists"]:
            health_score += 10
        
        table_score = (len([c for c in db_validation["table_counts"].values() if c > 0]) / 7) * 20
        health_score += table_score
        
        if db_validation["data_consistency"].get("doc_content_match", False):
            health_score += 10
        
        # å¤„ç†ç»“æœéªŒè¯ (40åˆ†)
        if results_validation["file_exists"]:
            health_score += 5
        
        if results_validation["json_valid"]:
            health_score += 5
        
        if results_validation["summary_complete"]:
            health_score += 10
        
        success_rate = (results_validation["successful_results"] / 
                       max(results_validation["results_count"], 1)) * 20
        health_score += success_rate
        
        # æ€§èƒ½è¯„åˆ† (20åˆ†)
        performance_score = (performance_benchmark.get("overall_score", 0) / 10) * 20
        health_score += performance_score
        
        # åˆ›å»ºæŠ¥å‘Š
        report = {
            "validation_timestamp": datetime.now().isoformat(),
            "validation_duration_seconds": round(validation_time, 2),
            "overall_health_score": round(health_score, 1),
            "health_grade": self._get_health_grade(health_score),
            "database_validation": db_validation,
            "results_validation": results_validation,
            "performance_benchmark": performance_benchmark,
            "summary": {
                "total_documents_processed": results_validation.get("results_count", 0),
                "successful_extractions": results_validation.get("successful_results", 0),
                "database_records": db_validation.get("table_counts", {}).get("pdf_documents", 0),
                "categories_identified": len(results_validation.get("categories_found", [])),
                "extraction_methods_used": results_validation.get("methods_used", []),
                "total_issues_found": (len(db_validation.get("issues", [])) + 
                                     len(results_validation.get("issues", [])))
            },
            "recommendations": self._generate_recommendations(db_validation, results_validation, performance_benchmark)
        }
        
        return report
    
    def _get_health_grade(self, score: float) -> str:
        """è·å–å¥åº·ç­‰çº§"""
        if score >= 90:
            return "A - ä¼˜ç§€"
        elif score >= 80:
            return "B - è‰¯å¥½"
        elif score >= 70:
            return "C - ä¸€èˆ¬"
        elif score >= 60:
            return "D - éœ€è¦æ”¹è¿›"
        else:
            return "F - ä¸¥é‡é—®é¢˜"
    
    def _generate_recommendations(self, db_validation: Dict, results_validation: Dict, 
                                performance_benchmark: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # æ•°æ®åº“å»ºè®®
        if db_validation.get("issues"):
            recommendations.append("ä¿®å¤æ•°æ®åº“å®Œæ•´æ€§é—®é¢˜")
        
        # æˆåŠŸç‡å»ºè®®
        success_rate = (results_validation.get("successful_results", 0) / 
                       max(results_validation.get("results_count", 1), 1)) * 100
        
        if success_rate < 70:
            recommendations.append("ä¼˜åŒ–PDFæå–ç®—æ³•ä»¥æé«˜æˆåŠŸç‡")
        elif success_rate < 90:
            recommendations.append("è°ƒä¼˜æå–å‚æ•°ä»¥è¿›ä¸€æ­¥æé«˜æˆåŠŸç‡")
        
        # æ€§èƒ½å»ºè®®
        performance_recs = performance_benchmark.get("recommendations", [])
        recommendations.extend(performance_recs)
        
        # æ•°æ®è´¨é‡å»ºè®®
        if results_validation.get("categories_found"):
            if len(results_validation["categories_found"]) < 5:
                recommendations.append("è€ƒè™‘æ”¹è¿›åˆ†ç±»ç®—æ³•ä»¥è¯†åˆ«æ›´å¤šç±»åˆ«")
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹ç³»ç»Ÿæ•´ä½“æ€§èƒ½å’Œæ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("=" * 60)
    
    # é…ç½®è·¯å¾„
    db_path = "/mnt/d/desktop/appp/database/yixue_knowledge_base.db"
    results_file = "/mnt/d/desktop/appp/structured_data/quick_results_20250808_080059.json"
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = SystemValidator(db_path, results_file)
    
    try:
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        report = validator.generate_validation_report()
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = "/mnt/d/desktop/appp/system_validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"âœ… ç³»ç»ŸéªŒè¯å®Œæˆ!")
        print(f"â±ï¸ éªŒè¯è€—æ—¶: {report['validation_duration_seconds']} ç§’")
        print(f"ğŸ¥ ç³»ç»Ÿå¥åº·åº¦: {report['overall_health_score']}/100 ({report['health_grade']})")
        
        summary = report['summary']
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   ğŸ“„ æ€»æ–‡ä»¶æ•°: {summary['total_documents_processed']}")
        print(f"   âœ… æˆåŠŸæå–: {summary['successful_extractions']}")
        print(f"   ğŸ—„ï¸ æ•°æ®åº“è®°å½•: {summary['database_records']}")
        print(f"   ğŸ“š è¯†åˆ«åˆ†ç±»: {summary['categories_identified']} ç§")
        print(f"   ğŸ”§ ä½¿ç”¨æ–¹æ³•: {', '.join(summary['extraction_methods_used'])}")
        
        if summary['total_issues_found'] > 0:
            print(f"   âš ï¸ å‘ç°é—®é¢˜: {summary['total_issues_found']} ä¸ª")
        else:
            print(f"   âœ… æ— é‡è¦é—®é¢˜")
        
        print(f"\nğŸš€ æ€§èƒ½è¯„åˆ†: {report['performance_benchmark'].get('overall_score', 0)}/10")
        
        if report.get('recommendations'):
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"   {i}. {rec}")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # æœ€ç»ˆè¯„ä¼°
        if report['overall_health_score'] >= 80:
            print(f"\nğŸ‰ ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼ŒçŸ¥è¯†åº“æ„å»ºæˆåŠŸ!")
        elif report['overall_health_score'] >= 60:
            print(f"\nâš ï¸ ç³»ç»ŸåŸºæœ¬æ­£å¸¸ï¼Œå»ºè®®å…³æ³¨å‘ç°çš„é—®é¢˜")
        else:
            print(f"\nâŒ ç³»ç»Ÿå­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¿®å¤")
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()