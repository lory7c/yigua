# 📊 易卦应用数据处理完整方案

## 🎯 目标
将3.7GB的易学资料转化为：
- **核心数据包**：5-10MB（内置应用）
- **扩展数据包**：50-100MB（按需下载）
- **云端数据库**：完整知识图谱（API访问）

## 📁 数据集分析

### 现有数据类型
```
总大小：3.7GB
文件类型：
├── PDF文档 (90%)：古籍、注解、案例
├── 图片文件 (5%)：卦象图、示意图
├── 文本文件 (3%)：笔记、整理稿
└── 其他文件 (2%)：视频、音频
```

### 数据价值分级
```
🔴 核心数据（必需）
├── 64卦基础信息
├── 384爻辞
├── 五行生克关系
├── 天干地支
└── 基础起卦规则

🟡 重要数据（推荐）
├── 历代名家注解
├── 经典案例100例
├── 梅花易数口诀
├── 六爻断语集
└── 常用神煞

🟢 扩展数据（可选）
├── 完整古籍原文
├── 学术论文
├── 现代案例
└── 音视频教程
```

## 🔧 数据处理流程

### Phase 1：数据提取与清洗

#### 1.1 PDF文本提取
```python
# extract_pdf.py
import PyPDF2
import pdfplumber
import os
import json
from pathlib import Path

class PDFExtractor:
    def __init__(self, input_dir, output_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def extract_all(self):
        """批量提取所有PDF"""
        results = []
        pdf_files = list(self.input_dir.glob("*.pdf"))
        
        for pdf_file in pdf_files:
            print(f"处理: {pdf_file.name}")
            try:
                data = self.extract_single(pdf_file)
                results.append(data)
                
                # 保存单个文件的提取结果
                output_file = self.output_dir / f"{pdf_file.stem}.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                    
            except Exception as e:
                print(f"错误: {pdf_file.name} - {e}")
                
        return results
    
    def extract_single(self, pdf_path):
        """提取单个PDF"""
        with pdfplumber.open(pdf_path) as pdf:
            return {
                'filename': pdf_path.name,
                'metadata': self.classify_book(pdf_path.name),
                'pages': len(pdf.pages),
                'content': self.extract_content(pdf),
                'tables': self.extract_tables(pdf),
                'images_count': self.count_images(pdf)
            }
    
    def classify_book(self, filename):
        """自动分类书籍"""
        categories = {
            '六爻': ['六爻', '卜筮', '火珠林', '增删卜易'],
            '梅花': ['梅花', '易数', '观梅'],
            '八字': ['八字', '四柱', '命理', '子平'],
            '奇门': ['奇门', '遁甲'],
            '六壬': ['六壬', '大六壬', '壬占'],
            '紫微': ['紫微', '斗数'],
            '风水': ['风水', '堪舆', '玄空'],
            '综合': ['易经', '周易', '易学']
        }
        
        for category, keywords in categories.items():
            if any(kw in filename for kw in keywords):
                return {'category': category, 'importance': self.get_importance(filename)}
        
        return {'category': '其他', 'importance': 'low'}
    
    def get_importance(self, filename):
        """判断重要性"""
        core_books = ['增删卜易', '梅花易数', '周易', '易经', '火珠林']
        important_books = ['六爻', '千里命稿', '三命通会', '紫微斗数全书']
        
        if any(book in filename for book in core_books):
            return 'core'
        elif any(book in filename for book in important_books):
            return 'important'
        return 'extended'
    
    def extract_content(self, pdf):
        """提取文本内容"""
        content = []
        for i, page in enumerate(pdf.pages[:10]):  # 先提取前10页作为样本
            text = page.extract_text()
            if text:
                content.append({
                    'page': i + 1,
                    'text': text[:1000]  # 截取前1000字符
                })
        return content
    
    def extract_tables(self, pdf):
        """提取表格数据"""
        tables = []
        for i, page in enumerate(pdf.pages[:5]):
            page_tables = page.extract_tables()
            if page_tables:
                tables.append({
                    'page': i + 1,
                    'count': len(page_tables)
                })
        return tables
    
    def count_images(self, pdf):
        """统计图片数量"""
        # 简化版：统计页面中的图片数量
        return sum(1 for page in pdf.pages if page.images)

# 使用示例
if __name__ == "__main__":
    extractor = PDFExtractor("../data", "./extracted")
    results = extractor.extract_all()
    print(f"处理完成: {len(results)} 个文件")
```

#### 1.2 结构化知识提取
```python
# structure_knowledge.py
import json
import re
from typing import Dict, List

class KnowledgeStructurer:
    def __init__(self):
        self.hexagrams = {}
        self.interpretations = {}
        self.cases = []
        
    def process_yijing_text(self, text):
        """处理易经原文，提取64卦"""
        hexagram_pattern = r'(第\d+卦|[\u4e00-\u9fa5]{1,2}卦)'
        
        # 64卦基础信息
        self.hexagrams = {
            '乾': {'number': 1, 'symbol': '☰☰', 'element': '天', 'attribute': '刚健'},
            '坤': {'number': 2, 'symbol': '☷☷', 'element': '地', 'attribute': '柔顺'},
            '屯': {'number': 3, 'symbol': '☵☳', 'element': '水雷', 'attribute': '始生'},
            '蒙': {'number': 4, 'symbol': '☶☵', 'element': '山水', 'attribute': '启蒙'},
            # ... 继续添加其他60卦
        }
        
        # 提取卦辞和爻辞
        for name, info in self.hexagrams.items():
            info['judgment'] = self.extract_judgment(text, name)
            info['lines'] = self.extract_line_texts(text, name)
            
    def extract_judgment(self, text, hexagram_name):
        """提取卦辞"""
        pattern = f'{hexagram_name}[：:]([^。]+。)'
        match = re.search(pattern, text)
        return match.group(1) if match else ""
    
    def extract_line_texts(self, text, hexagram_name):
        """提取爻辞"""
        lines = []
        positions = ['初', '二', '三', '四', '五', '上']
        for pos in positions:
            pattern = f'{pos}[九六][：:]([^。]+。)'
            match = re.search(pattern, text)
            if match:
                lines.append({
                    'position': pos,
                    'text': match.group(1)
                })
        return lines
    
    def extract_cases(self, text, source):
        """提取占卜案例"""
        case_pattern = r'(例|案|占得?)[：:](.+?)(?=例|案|$)'
        matches = re.findall(case_pattern, text, re.DOTALL)
        
        for match in matches:
            case = self.parse_case(match[1])
            if case:
                case['source'] = source
                self.cases.append(case)
    
    def parse_case(self, case_text):
        """解析单个案例"""
        return {
            'question': self.extract_question(case_text),
            'hexagram': self.extract_hexagram(case_text),
            'analysis': self.extract_analysis(case_text),
            'result': self.extract_result(case_text)
        }
    
    def extract_question(self, text):
        """提取问题"""
        patterns = [r'问[：:](.+?)[。？]', r'占(.+?)[。，]', r'测(.+?)[。，]']
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)
        return ""
    
    def extract_hexagram(self, text):
        """提取卦象"""
        # 识别卦名
        for name in self.hexagrams.keys():
            if name in text:
                return name
        return ""
    
    def extract_analysis(self, text):
        """提取分析过程"""
        pattern = r'(析|解|断)[：:](.+?)(?=应验|结果|$)'
        match = re.search(pattern, text, re.DOTALL)
        return match.group(2) if match else text[:200]
    
    def extract_result(self, text):
        """提取结果"""
        pattern = r'(果|验|后来)[：:](.+?)$'
        match = re.search(pattern, text)
        return match.group(2) if match else ""
    
    def save_structured_data(self, output_dir):
        """保存结构化数据"""
        # 1. 保存核心数据（给应用使用）
        core_data = {
            'hexagrams': self.hexagrams,
            'basic_interpretations': self.get_basic_interpretations()
        }
        
        with open(f'{output_dir}/core_data.json', 'w', encoding='utf-8') as f:
            json.dump(core_data, f, ensure_ascii=False, indent=2)
        
        # 2. 保存扩展数据（按需加载）
        extended_data = {
            'detailed_interpretations': self.interpretations,
            'cases': self.cases[:100]  # 精选100个案例
        }
        
        with open(f'{output_dir}/extended_data.json', 'w', encoding='utf-8') as f:
            json.dump(extended_data, f, ensure_ascii=False, indent=2)
    
    def get_basic_interpretations(self):
        """获取基础解释（精简版）"""
        # 每个卦只保留100字的核心解释
        basic = {}
        for hex_name, interp in self.interpretations.items():
            basic[hex_name] = interp[:100] if len(interp) > 100 else interp
        return basic
```

### Phase 2：数据分级存储

#### 2.1 SQLite数据库设计
```python
# create_database.py
import sqlite3
import json
from pathlib import Path

class DatabaseBuilder:
    def __init__(self, db_path='yigua.db'):
        self.conn = sqlite3.connect(db_path)
        self.cursor = self.conn.cursor()
        self.create_tables()
    
    def create_tables(self):
        """创建数据表"""
        
        # 1. 卦象表（核心）
        self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS hexagrams (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL UNIQUE,
            number INTEGER,
            symbol TEXT,
            upper_trigram TEXT,
            lower_trigram TEXT,
            element TEXT,
            attribute TEXT,
            judgment TEXT,
            image TEXT,
            size_bytes INTEGER DEFAULT 0
        )''')
        
        # 2. 爻辞表（核心）
        self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS line_texts (
            id INTEGER PRIMARY KEY,
            hexagram_id INTEGER,
            position INTEGER,
            yin_yang TEXT,
            text TEXT,
            interpretation TEXT,
            FOREIGN KEY (hexagram_id) REFERENCES hexagrams(id)
        )''')
        
        # 3. 解释表（扩展）
        self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS interpretations (
            id INTEGER PRIMARY KEY,
            hexagram_id INTEGER,
            type TEXT,  -- 'classic', 'modern', 'expert'
            author TEXT,
            content TEXT,
            source TEXT,
            importance INTEGER DEFAULT 0,
            FOREIGN KEY (hexagram_id) REFERENCES hexagrams(id)
        )''')
        
        # 4. 案例表（扩展）
        self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS cases (
            id INTEGER PRIMARY KEY,
            title TEXT,
            category TEXT,
            hexagram_id INTEGER,
            question TEXT,
            date TEXT,
            method TEXT,
            analysis TEXT,
            result TEXT,
            accuracy INTEGER,
            source TEXT,
            tags TEXT,
            FOREIGN KEY (hexagram_id) REFERENCES hexagrams(id)
        )''')
        
        # 5. 知识图谱关系表
        self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS relations (
            id INTEGER PRIMARY KEY,
            source_type TEXT,
            source_id INTEGER,
            target_type TEXT,  
            target_id INTEGER,
            relation_type TEXT,
            weight REAL DEFAULT 1.0
        )''')
        
        # 6. 创建全文搜索索引
        self.cursor.execute('''
        CREATE VIRTUAL TABLE IF NOT EXISTS search_index USING fts5(
            title,
            content,
            tags,
            tokenize='unicode61'
        )''')
        
        self.conn.commit()
    
    def import_core_data(self, json_path):
        """导入核心数据"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # 导入64卦
        for name, info in data['hexagrams'].items():
            self.cursor.execute('''
                INSERT OR REPLACE INTO hexagrams 
                (name, number, symbol, element, attribute, judgment)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (name, info['number'], info['symbol'], 
                  info['element'], info['attribute'], info.get('judgment', '')))
            
            # 导入爻辞
            hexagram_id = self.cursor.lastrowid
            for line in info.get('lines', []):
                self.cursor.execute('''
                    INSERT INTO line_texts
                    (hexagram_id, position, text)
                    VALUES (?, ?, ?)
                ''', (hexagram_id, line['position'], line['text']))
        
        self.conn.commit()
        print(f"导入{len(data['hexagrams'])}个卦象")
    
    def analyze_data_size(self):
        """分析数据大小"""
        tables = ['hexagrams', 'line_texts', 'interpretations', 'cases']
        total_size = 0
        
        for table in tables:
            self.cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = self.cursor.fetchone()[0]
            
            # 估算每个表的大小
            self.cursor.execute(f"SELECT * FROM {table} LIMIT 1")
            if self.cursor.fetchone():
                # 简单估算：每行约500字节
                size = count * 500
                total_size += size
                print(f"{table}: {count}条记录, 约{size/1024:.1f}KB")
        
        print(f"总大小: 约{total_size/1024/1024:.1f}MB")
        return total_size
    
    def export_for_app(self, output_dir):
        """导出应用所需的数据"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # 1. 导出核心数据（内置到APK）
        self.cursor.execute('''
            SELECT name, number, symbol, element, attribute, judgment
            FROM hexagrams
            ORDER BY number
        ''')
        
        hexagrams = []
        for row in self.cursor.fetchall():
            hexagrams.append({
                'name': row[0],
                'number': row[1],
                'symbol': row[2],
                'element': row[3],
                'attribute': row[4],
                'judgment': row[5][:100]  # 只保留100字
            })
        
        core_db = {
            'version': '1.0',
            'hexagrams': hexagrams,
            'size_kb': len(json.dumps(hexagrams)) / 1024
        }
        
        with open(output_dir / 'core.json', 'w', encoding='utf-8') as f:
            json.dump(core_db, f, ensure_ascii=False)
        
        print(f"核心数据: {core_db['size_kb']:.1f}KB")
        
        # 2. 导出扩展数据包（按需下载）
        packages = {
            'interpretations': self.export_interpretations(),
            'cases': self.export_cases(),
            'advanced': self.export_advanced()
        }
        
        for name, data in packages.items():
            with open(output_dir / f'{name}.json', 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False)
            size = len(json.dumps(data)) / 1024
            print(f"{name}包: {size:.1f}KB")
    
    def export_interpretations(self):
        """导出解释包"""
        self.cursor.execute('''
            SELECT h.name, i.type, i.author, i.content
            FROM interpretations i
            JOIN hexagrams h ON i.hexagram_id = h.id
            WHERE i.importance > 5
            LIMIT 1000
        ''')
        
        return [
            {
                'hexagram': row[0],
                'type': row[1],
                'author': row[2],
                'content': row[3][:500]  # 限制长度
            }
            for row in self.cursor.fetchall()
        ]
    
    def export_cases(self):
        """导出案例包"""
        self.cursor.execute('''
            SELECT c.title, h.name, c.question, c.analysis, c.result
            FROM cases c
            JOIN hexagrams h ON c.hexagram_id = h.id
            WHERE c.accuracy > 7
            LIMIT 100
        ''')
        
        return [
            {
                'title': row[0],
                'hexagram': row[1],
                'question': row[2],
                'analysis': row[3][:300],
                'result': row[4]
            }
            for row in self.cursor.fetchall()
        ]
    
    def export_advanced(self):
        """导出高级功能包"""
        # 导出知识图谱关系等高级数据
        return {
            'relations': [],
            'advanced_algorithms': [],
            'expert_rules': []
        }
    
    def close(self):
        self.conn.close()

# 使用示例
if __name__ == "__main__":
    builder = DatabaseBuilder()
    builder.import_core_data('./extracted/core_data.json')
    builder.analyze_data_size()
    builder.export_for_app('./app_data')
    builder.close()
```

### Phase 3：云端API设计

#### 3.1 Serverless API (使用Vercel)
```javascript
// api/knowledge.js
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_KEY
)

export default async function handler(req, res) {
  const { method, query, body } = req
  
  switch (method) {
    case 'GET':
      return handleGet(query, res)
    case 'POST':
      return handlePost(body, res)
    default:
      res.status(405).json({ error: 'Method not allowed' })
  }
}

async function handleGet(query, res) {
  const { type, id, search } = query
  
  if (search) {
    // 全文搜索
    const { data, error } = await supabase
      .from('knowledge')
      .select('*')
      .textSearch('content', search)
      .limit(20)
    
    return res.status(200).json({ results: data })
  }
  
  if (type === 'hexagram' && id) {
    // 获取卦象详细信息
    const { data } = await supabase
      .from('hexagrams')
      .select(`
        *,
        interpretations (
          type,
          content,
          author
        ),
        cases (
          title,
          question,
          analysis
        )
      `)
      .eq('id', id)
      .single()
    
    return res.status(200).json(data)
  }
  
  // 获取数据包信息
  const packages = {
    core: { size: '5MB', version: '1.0', free: true },
    cases: { size: '15MB', version: '1.0', free: false },
    advanced: { size: '30MB', version: '1.0', free: false }
  }
  
  res.status(200).json({ packages })
}

async function handlePost(body, res) {
  const { action, data } = body
  
  if (action === 'ai_interpret') {
    // AI解读（调用OpenAI或本地模型）
    const interpretation = await getAIInterpretation(data)
    return res.status(200).json({ interpretation })
  }
  
  if (action === 'save_record') {
    // 保存用户占卜记录
    const { data: record } = await supabase
      .from('user_records')
      .insert(data)
      .select()
      .single()
    
    return res.status(201).json(record)
  }
  
  res.status(400).json({ error: 'Invalid action' })
}
```

## 📱 应用集成方案

### Flutter端数据服务
```dart
// lib/services/data_service_v2.dart
class DataServiceV2 {
  static const String baseUrl = 'https://your-api.vercel.app/api';
  
  // 本地数据库
  late Database localDB;
  
  // 数据策略
  final DataStrategy strategy = DataStrategy();
  
  Future<void> initialize() async {
    // 1. 初始化本地数据库
    localDB = await openDatabase(
      'yigua_local.db',
      version: 1,
      onCreate: (db, version) {
        // 创建本地表
      },
    );
    
    // 2. 加载核心数据
    await loadCoreData();
    
    // 3. 检查更新
    checkForUpdates();
  }
  
  Future<void> loadCoreData() async {
    // 从assets加载核心数据
    final String jsonString = await rootBundle.loadString(
      'assets/data/core.json'
    );
    final coreData = json.decode(jsonString);
    
    // 存入本地数据库
    for (var hexagram in coreData['hexagrams']) {
      await localDB.insert('hexagrams', hexagram);
    }
  }
  
  Future<HexagramData> getHexagram(String name) async {
    // 优先本地
    var data = await localDB.query(
      'hexagrams',
      where: 'name = ?',
      whereArgs: [name],
    );
    
    if (data.isEmpty && hasNetwork()) {
      // 从云端获取
      data = await fetchFromCloud('/hexagram/$name');
      // 缓存到本地
      await localDB.insert('hexagrams', data);
    }
    
    return HexagramData.fromMap(data.first);
  }
  
  Future<List<Case>> searchCases(String keyword) async {
    // 搜索需要网络
    if (!hasNetwork()) {
      return getCachedCases(keyword);
    }
    
    final response = await http.get(
      Uri.parse('$baseUrl/knowledge?search=$keyword'),
    );
    
    final cases = json.decode(response.body)['results'];
    return cases.map((c) => Case.fromMap(c)).toList();
  }
  
  Future<void> downloadPackage(String packageId) async {
    // 下载扩展包
    final url = '$baseUrl/packages/$packageId';
    final response = await http.get(Uri.parse(url));
    
    if (response.statusCode == 200) {
      final data = json.decode(response.body);
      
      // 存储到本地
      await savePackageData(packageId, data);
      
      // 更新配置
      await updatePackageStatus(packageId, 'downloaded');
    }
  }
}
```

## 🚀 实施计划

### Week 1: 数据提取
- [ ] 运行PDF提取脚本
- [ ] 整理分类数据
- [ ] 生成结构化JSON

### Week 2: 数据库构建
- [ ] 创建SQLite数据库
- [ ] 导入核心数据
- [ ] 生成数据包

### Week 3: 云端部署
- [ ] 部署Supabase/Vercel
- [ ] 上传扩展数据
- [ ] 测试API接口

### Week 4: 应用集成
- [ ] 集成本地数据
- [ ] 实现云端同步
- [ ] 测试离线功能

## 💾 预期成果

### 数据包大小
```
核心包：5MB（必需，内置APK）
├── 64卦基础：1MB
├── 384爻辞：2MB
├── 五行关系：0.5MB
└── 基础算法：1.5MB

扩展包1：15MB（六爻专业）
├── 历代注解：8MB
├── 经典案例：5MB
└── 断语集：2MB

扩展包2：20MB（梅花易数）
扩展包3：25MB（八字命理）
```

### 性能指标
- 离线查询：<10ms
- 在线搜索：<500ms
- 数据同步：增量更新
- 存储占用：30-100MB（含缓存）

这个方案可以让你的3.7GB数据变成高效可用的知识库系统！